{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "from skimage.filters import threshold_local\n",
    "from pyimagesearch.transform import four_point_transform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and show the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'b.jpg'\n",
    "big_img = cv2.imread(img_path)\n",
    "cv2.imshow('org img',big_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = big_img.shape[0] / 500.0 # ratio used later\n",
    "org = big_img.copy() #keep a  copy of original image\n",
    "# Resizing the image and making the height to 500 keeping the aspect ratio constant.\n",
    "img = imutils.resize(big_img, height = 500)\n",
    "cv2.imshow('resizing',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are converting our BGR image to a grayscale image.\n",
    "Here we are using Gaussian Blur to remove the Gaussian Noise from the image.\n",
    "Also, we are simply finding the edges in the image using Canny Edge Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img = cv2.cvtColor(img.copy(),cv2.COLOR_BGR2GRAY)\n",
    "blur_img = cv2.GaussianBlur(gray_img,(5,5),0)\n",
    "edged_img = cv2.Canny(blur_img,75,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('edged',edged_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all the contours in the image and\n",
    " Sorting the contours in descending order based on their contour area and just taking the first 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts,_ = cv2.findContours(edged_img.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts,key=cv2.contourArea,reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traversing in contours and finding the contour with 4 sides using cv2.approxPolyDP()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c,True)\n",
    "    approx = cv2.approxPolyDP(c,0.02*peri,True)\n",
    "    if len(approx)==4:\n",
    "        doc = approx\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are simply drawing points/circles around the corners of the document. These are the points that we got above in the contour detection step using the CHAIN_APPROX_SIMPLE method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[]\n",
    "for d in doc:\n",
    "    tuple_point = tuple(d[0])\n",
    "    cv2.circle(img,tuple_point,3,(0,0,255),4)\n",
    "    p.append(tuple_point)\n",
    "cv2.imshow('Corner points detected',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We are applying the four-point transformation to the image. It means that we will only extract the document from the image. \n",
    " Or we can also say that we just want to extract the rectangle formed by the four points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = four_point_transform(org, doc.reshape(4, 2) * ratio)\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Warped\", imutils.resize(warped, height = 650))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold the image to give it a black and white feel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = threshold_local(warped, 11, offset = 10, method = \"gaussian\")\n",
    "warped = (warped > T).astype(\"uint8\") * 255\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# destroy all widows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46c5b148c974be58c6a55f6ce7e628c26ca603441918bb5a155f2d731e5a5c43"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
